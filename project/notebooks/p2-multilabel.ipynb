{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8614a4dd",
   "metadata": {},
   "source": [
    "### Multi-label classification on FMA\n",
    "\n",
    "Recast genre classification as a multilabel problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e8aa843",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import IPython.display as ipd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "import utils\n",
    "import top_genres\n",
    "\n",
    "RANDOM_STATE = 53"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb121d0",
   "metadata": {},
   "source": [
    "### Load features and tracks\n",
    "\n",
    "* enrich tracks with top_genre1, top_genre2\n",
    "\n",
    "note: genre enrichment takes a minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9437f47d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(106574, 57)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(features, tracks) = utils.load_features()\n",
    "genres =  utils.load_genres()\n",
    "\n",
    "# enrich tracks with top_genres\n",
    "top_genres.add_top_genres(tracks, genres)\n",
    "tracks.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66552330",
   "metadata": {},
   "source": [
    "### Create a multilabel dataset using top_genre1 and top_genre2\n",
    "\n",
    "* drop easy listening and spoken (small support, oddball categories)\n",
    "* choose tracks with top_genre_count <= 3\n",
    "* Use entire dataset; will be imbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bab286ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "prune = ~(tracks[('track','top_genre1')].isin(['Spoken','Easy Listening']) |\n",
    "    tracks[('track','top_genre2')].isin(['Spoken','Easy Listening']) |\n",
    "    tracks[('track','top_genre3')].isin(['Spoken','Easy Listening']))\n",
    "\n",
    "f1 = features[prune]\n",
    "t1 = tracks[prune]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a46bcc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "keep = (t1[('track','top_genre_count')] < 4) & (t1[('track','top_genre_type')].isin(['major','hybrid']))\n",
    "t1 = t1[keep].copy()\n",
    "f1 = f1[keep].copy()\n",
    "\n",
    "# generate label set and append to t1\n",
    "tops = t1[[('track','top_genre1'),('track','top_genre2')]].values.tolist()\n",
    "tops = [[j for j in i if j] for i in tops]\n",
    "t1[('track'),('top_genre_list')] = tops\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e430e9ed",
   "metadata": {},
   "source": [
    "### binarize label set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a2b5023",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(87151, 14)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "X = f1\n",
    "\n",
    "y = t1[('track'),('top_genre_list')]\n",
    "mlb = MultiLabelBinarizer()\n",
    "mlb.fit(y)\n",
    "y = mlb.transform(y)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db37e944",
   "metadata": {},
   "source": [
    "### Examine the frequency of each label in the multi-label set\n",
    "\n",
    "* we see that it is pretty unbalanced - Rock/Experimental/Jazz > 25,000, others < 1,000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99c4b77d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Hip-Hop': 6810,\n",
       " 'Pop': 9076,\n",
       " 'Folk': 8272,\n",
       " 'Rock': 25554,\n",
       " 'Experimental': 28001,\n",
       " 'Jazz': 2359,\n",
       " 'Electronic': 26084,\n",
       " 'International': 3623,\n",
       " 'Instrumental': 9079,\n",
       " 'Blues': 689,\n",
       " 'Soul-RnB': 926,\n",
       " 'Old-Time / Historic': 792,\n",
       " 'Classical': 2695,\n",
       " 'Country': 1191}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def count_labels(y):\n",
    "    label_counts = defaultdict(int)\n",
    "    for blabels in y:\n",
    "        for i in range(len(blabels)):\n",
    "            if blabels[i]:\n",
    "                label_counts[mlb.classes_[i]] += 1\n",
    "\n",
    "    return dict(label_counts)\n",
    "\n",
    "count_labels(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4026b11c",
   "metadata": {},
   "source": [
    "### Build train/test datasets\n",
    "\n",
    "* without under/oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac1ec86d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(69720, 14) (17431, 14)\n",
      "{'Folk': 6659, 'Pop': 7257, 'Rock': 20441, 'Experimental': 22428, 'Electronic': 20817, 'Classical': 2158, 'Jazz': 1881, 'International': 2891, 'Instrumental': 7282, 'Hip-Hop': 5460, 'Country': 960, 'Soul-RnB': 727, 'Blues': 550, 'Old-Time / Historic': 631}\n",
      "{'Experimental': 5573, 'Electronic': 5267, 'Instrumental': 1797, 'Hip-Hop': 1350, 'Classical': 537, 'Rock': 5113, 'Folk': 1613, 'Jazz': 478, 'Pop': 1819, 'Blues': 139, 'International': 732, 'Soul-RnB': 199, 'Country': 231, 'Old-Time / Historic': 161}\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=RANDOM_STATE,\n",
    "                                                    shuffle=True)\n",
    "\n",
    "scaler = MinMaxScaler(copy=False)\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "print(y_train.shape, y_test.shape)\n",
    "print(count_labels(y_train))\n",
    "print(count_labels(y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fdc889f",
   "metadata": {},
   "source": [
    "### Train MLPClassifier with defaults\n",
    "\n",
    "NOTE: will take a few minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f18c9e0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(max_iter=1000, random_state=53)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl1 = MLPClassifier(max_iter=1000, random_state=RANDOM_STATE)\n",
    "cl1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5da108",
   "metadata": {},
   "source": [
    "### Examine what prediction looks like\n",
    "\n",
    "* we can examine prediction probabilities - probability of each genre\n",
    "* since it's a multilabel problem, MLPClassifier automatically converts it a multilabel prediction for us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bbe963da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.32311224e-04, 6.12750287e-03, 7.08087414e-05, 1.43214400e-01,\n",
       "        9.17763730e-01, 5.27479993e-02, 2.03602122e-02, 9.52826222e-02,\n",
       "        1.13800623e-03, 2.94989496e-02, 8.61440099e-07, 4.98122534e-02,\n",
       "        7.30919992e-02, 5.78823986e-04]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yp_pred = cl1.predict_proba(X_test)\n",
    "yp_pred[0:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40eed4d",
   "metadata": {},
   "source": [
    "### it appears MLPClassifier only predicts a positive if > 50%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03a1b1fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.86087203e-03 1.92798975e-05 2.90843967e-02 3.66304377e-03\n",
      " 2.98989294e-02 2.40836169e-02 1.52075495e-03 5.88636759e-04\n",
      " 2.04422827e-02 5.93362784e-03 1.46660001e-07 1.72776376e-01\n",
      " 9.68741172e-01 5.63375679e-03]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "y_pred = cl1.predict(X_test)\n",
    "print(yp_pred[18])\n",
    "print(y_pred[18])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a08c800",
   "metadata": {},
   "source": [
    "### Scoring the classifier\n",
    "\n",
    "* accuracy will look for an exact match\n",
    "* this is a harsh metric; no credit for partial match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ba35b0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.32075038724112215"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_test, y_pred,  normalize=True, sample_weight=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c91285b",
   "metadata": {},
   "source": [
    "### Haming loss measures 'distance' between set of predicted labels vs set of true labels\n",
    "\n",
    "* because our labels are sparse, this is not a good measure.\n",
    "* for example, predicting all 0 will produce a similar Hamming score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73f6ca2c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07571076161518477\n",
      "0.10248162141340961\n"
     ]
    }
   ],
   "source": [
    "print(metrics.hamming_loss(y_test, y_pred))\n",
    "z = np.zeros(y_test.shape)\n",
    "print(metrics.hamming_loss(y_test, z))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5745ab87",
   "metadata": {},
   "source": [
    "### precision / recall from classification report\n",
    "\n",
    "* on a per label basis.\n",
    "* recall is poor across the board\n",
    "* this is probably due to underpredicting. perhaps if we lower the prediction threshold?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "619f8e58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     precision    recall  f1-score   support\n",
      "\n",
      "              Blues       1.00      0.01      0.01       139\n",
      "          Classical       0.85      0.40      0.54       537\n",
      "            Country       0.00      0.00      0.00       231\n",
      "         Electronic       0.79      0.40      0.54      5267\n",
      "       Experimental       0.66      0.64      0.65      5573\n",
      "               Folk       0.70      0.32      0.44      1613\n",
      "            Hip-Hop       0.77      0.29      0.42      1350\n",
      "       Instrumental       0.62      0.12      0.20      1797\n",
      "      International       0.72      0.18      0.29       732\n",
      "               Jazz       0.51      0.15      0.24       478\n",
      "Old-Time / Historic       0.96      0.72      0.82       161\n",
      "                Pop       0.41      0.03      0.06      1819\n",
      "               Rock       0.78      0.61      0.69      5113\n",
      "           Soul-RnB       0.00      0.00      0.00       199\n",
      "\n",
      "          micro avg       0.72      0.42      0.53     25009\n",
      "          macro avg       0.63      0.28      0.35     25009\n",
      "       weighted avg       0.70      0.42      0.50     25009\n",
      "        samples avg       0.55      0.47      0.49     25009\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\orovi\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\orovi\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "my_metrics = metrics.classification_report( y_test, y_pred, target_names=mlb.classes_)\n",
    "print(my_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e657147f",
   "metadata": {},
   "source": [
    "### investigate/confirm f1 score from classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1fcad0cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0]\n",
      "5450 11981 1869 1992 3581 9989\n",
      "0.6570642201834862 0.6425623542077875\n"
     ]
    }
   ],
   "source": [
    "y_prednp = np.array(y_pred)\n",
    "y_prednp.shape\n",
    "p4 = y_prednp[:,4]\n",
    "\n",
    "y_testnp = np.array(y_test)\n",
    "t4 = y_testnp[:,4]\n",
    "\n",
    "d = p4 - t4\n",
    "print(d[0:3])\n",
    "pos = np.sum(p4 > 0)\n",
    "neg = np.sum(p4 == 0)\n",
    "fp = np.sum(d > 0)\n",
    "fn = np.sum(d < 0)\n",
    "tp = pos- fp\n",
    "tn = neg - fn\n",
    "print(pos, neg, fp, fn, tp, tn)\n",
    "\n",
    "precision = tp/(tp+fp)\n",
    "recall = tp/(tp+fn)\n",
    "print(precision, recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434455c6",
   "metadata": {},
   "source": [
    "### Rudimentary attempt to lower prediction probablity threshold\n",
    "\n",
    "* note: we would prefer this as an option to MLPClassifier so that it would train on these labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "66068e01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2 0.433847240165463\n",
      "0.25 0.43224623870464424\n",
      "0.3 0.42694022006081955\n",
      "0.35 0.41428545212213014\n",
      "0.4 0.39799155680827986\n",
      "0.44999999999999996 0.3714522239406773\n",
      "0.5 0.34960747488672383\n"
     ]
    }
   ],
   "source": [
    "yp_pred = np.array(cl1.predict_proba(X_test))\n",
    "for prob in np.linspace(.2,.5, 7):\n",
    "    y_pred = (yp_pred > prob).astype(int)\n",
    "    print(prob, metrics.f1_score(y_test, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad92fe9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     precision    recall  f1-score   support\n",
      "\n",
      "              Blues       0.83      0.04      0.07       139\n",
      "          Classical       0.63      0.49      0.55       537\n",
      "            Country       0.35      0.04      0.07       231\n",
      "         Electronic       0.67      0.66      0.67      5267\n",
      "       Experimental       0.53      0.82      0.65      5573\n",
      "               Folk       0.52      0.53      0.52      1613\n",
      "            Hip-Hop       0.63      0.43      0.51      1350\n",
      "       Instrumental       0.48      0.30      0.37      1797\n",
      "      International       0.55      0.34      0.42       732\n",
      "               Jazz       0.34      0.31      0.33       478\n",
      "Old-Time / Historic       0.94      0.76      0.84       161\n",
      "                Pop       0.32      0.27      0.30      1819\n",
      "               Rock       0.62      0.77      0.69      5113\n",
      "           Soul-RnB       0.00      0.00      0.00       199\n",
      "\n",
      "          micro avg       0.57      0.61      0.59     25009\n",
      "          macro avg       0.53      0.41      0.43     25009\n",
      "       weighted avg       0.56      0.61      0.57     25009\n",
      "        samples avg       0.61      0.65      0.60     25009\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\orovi\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_pred = (yp_pred > .30).astype(int)\n",
    "my_metrics = metrics.classification_report( y_test, y_pred, target_names=mlb.classes_)\n",
    "print(my_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a82ccf",
   "metadata": {},
   "source": [
    "### We see substantial improvement across the board\n",
    "### Try upsampling\n",
    "\n",
    "* However poorly supported genres still don't perform well.\n",
    "* Multilabel upsampling is not well-defined\n",
    "* our rudimentary attempt is simply to duplicate all tracks outside the top 3 one time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cf49f750",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb = MultiLabelBinarizer()\n",
    "mlb.fit(t1[('track'),('top_genre_list')])\n",
    "\n",
    "f1_train, f1_test, t1_train, t1_test = train_test_split(f1,t1, \n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=RANDOM_STATE,\n",
    "                                                    shuffle=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4dc79f78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((69720, 58), (16036, 58))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "up = ~(t1_train[('track','top_genre1')].isin(['Experimental','Electronic','Rock']) |\n",
    "    t1_train[('track','top_genre2')].isin(['Experimental','Electronic','Rock']))\n",
    "t1_train.shape, t1_train[up].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "980b504e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((85756, 518), (85756, 58))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2 = t1_train.append(t1_train[up])\n",
    "f2 = f1_train.append(f1_train[up])\n",
    "f2.shape, t2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d982b70b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(85756, 14) (17431, 14)\n",
      "{'Folk': 11017, 'Pop': 10529, 'Rock': 20441, 'Experimental': 22428, 'Electronic': 20817, 'Classical': 3608, 'Jazz': 2639, 'International': 4840, 'Instrumental': 10068, 'Hip-Hop': 8908, 'Country': 1613, 'Soul-RnB': 1173, 'Blues': 882, 'Old-Time / Historic': 1226}\n",
      "{'Experimental': 5573, 'Electronic': 5267, 'Instrumental': 1797, 'Hip-Hop': 1350, 'Classical': 537, 'Rock': 5113, 'Folk': 1613, 'Jazz': 478, 'Pop': 1819, 'Blues': 139, 'International': 732, 'Soul-RnB': 199, 'Country': 231, 'Old-Time / Historic': 161}\n"
     ]
    }
   ],
   "source": [
    "X_train = f2\n",
    "X_test = f1_test\n",
    "y_train = mlb.transform(t2[('track'),('top_genre_list')])\n",
    "y_test = mlb.transform(t1_test[('track'),('top_genre_list')])\n",
    "\n",
    "####\n",
    "scaler = MinMaxScaler(copy=False)\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "print(y_train.shape, y_test.shape)\n",
    "print(count_labels(y_train))\n",
    "print(count_labels(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "932ca282",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(max_iter=1000, random_state=53)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl2 = MLPClassifier(max_iter=1000, random_state=RANDOM_STATE)\n",
    "cl2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "581c1305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     precision    recall  f1-score   support\n",
      "\n",
      "              Blues       1.00      0.05      0.10       139\n",
      "          Classical       0.75      0.46      0.57       537\n",
      "            Country       0.20      0.01      0.02       231\n",
      "         Electronic       0.75      0.50      0.60      5267\n",
      "       Experimental       0.70      0.55      0.62      5573\n",
      "               Folk       0.63      0.43      0.51      1613\n",
      "            Hip-Hop       0.59      0.50      0.54      1350\n",
      "       Instrumental       0.61      0.12      0.20      1797\n",
      "      International       0.62      0.29      0.40       732\n",
      "               Jazz       0.75      0.09      0.15       478\n",
      "Old-Time / Historic       0.95      0.74      0.83       161\n",
      "                Pop       0.59      0.01      0.01      1819\n",
      "               Rock       0.83      0.56      0.67      5113\n",
      "           Soul-RnB       0.00      0.00      0.00       199\n",
      "\n",
      "          micro avg       0.73      0.43      0.54     25009\n",
      "          macro avg       0.64      0.31      0.37     25009\n",
      "       weighted avg       0.70      0.43      0.51     25009\n",
      "        samples avg       0.56      0.48      0.50     25009\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\orovi\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\orovi\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_pred = cl2.predict(X_test)\n",
    "my_metrics = metrics.classification_report( y_test, y_pred, target_names=mlb.classes_)\n",
    "print(my_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f7c8cc",
   "metadata": {},
   "source": [
    "### We see a modest performance improvement over our initial attempt\n",
    "\n",
    "* Try loosening the probability threshold as before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5d2c1b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2 0.434711916882421\n",
      "0.25 0.4323520233647122\n",
      "0.3 0.42233055442781936\n",
      "0.35 0.4129627547470914\n",
      "0.4 0.4003222395468951\n",
      "0.44999999999999996 0.3851358852324299\n",
      "0.5 0.37289388125600276\n"
     ]
    }
   ],
   "source": [
    "yp_pred = np.array(cl2.predict_proba(X_test))\n",
    "for prob in np.linspace(.2,.5, 7):\n",
    "    y_pred = (yp_pred > prob).astype(int)\n",
    "    print(prob, metrics.f1_score(y_test, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7bc90046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     precision    recall  f1-score   support\n",
      "\n",
      "              Blues       0.30      0.14      0.20       139\n",
      "          Classical       0.60      0.55      0.58       537\n",
      "            Country       0.19      0.33      0.24       231\n",
      "         Electronic       0.62      0.76      0.68      5267\n",
      "       Experimental       0.60      0.75      0.67      5573\n",
      "               Folk       0.41      0.68      0.51      1613\n",
      "            Hip-Hop       0.50      0.58      0.54      1350\n",
      "       Instrumental       0.48      0.34      0.40      1797\n",
      "      International       0.52      0.39      0.44       732\n",
      "               Jazz       0.40      0.36      0.38       478\n",
      "Old-Time / Historic       0.91      0.77      0.84       161\n",
      "                Pop       0.34      0.35      0.34      1819\n",
      "               Rock       0.65      0.75      0.69      5113\n",
      "           Soul-RnB       0.22      0.06      0.09       199\n",
      "\n",
      "          micro avg       0.56      0.64      0.60     25009\n",
      "          macro avg       0.48      0.49      0.47     25009\n",
      "       weighted avg       0.56      0.64      0.59     25009\n",
      "        samples avg       0.60      0.68      0.61     25009\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\orovi\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_pred = (yp_pred > .30).astype(int)\n",
    "my_metrics = metrics.classification_report( y_test, y_pred, target_names=mlb.classes_)\n",
    "print(my_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3b6a99",
   "metadata": {},
   "source": [
    "### Again we see improvement\n",
    "\n",
    "### Resize the network: hidden_layer_size=(300,)\n",
    "\n",
    "NOTE: SLOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6dfb8da6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(alpha=0.001, hidden_layer_sizes=(300,), max_iter=1000,\n",
       "              random_state=53)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl3 = MLPClassifier(max_iter=1000, hidden_layer_sizes=(300,), alpha=0.001, random_state=RANDOM_STATE)\n",
    "cl3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7c11e6fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     precision    recall  f1-score   support\n",
      "\n",
      "              Blues       0.50      0.06      0.11       139\n",
      "          Classical       0.73      0.47      0.57       537\n",
      "            Country       0.53      0.11      0.18       231\n",
      "         Electronic       0.75      0.51      0.61      5267\n",
      "       Experimental       0.78      0.44      0.56      5573\n",
      "               Folk       0.69      0.36      0.47      1613\n",
      "            Hip-Hop       0.47      0.62      0.54      1350\n",
      "       Instrumental       0.47      0.36      0.41      1797\n",
      "      International       0.68      0.32      0.44       732\n",
      "               Jazz       0.56      0.22      0.31       478\n",
      "Old-Time / Historic       0.93      0.83      0.88       161\n",
      "                Pop       0.41      0.17      0.24      1819\n",
      "               Rock       0.85      0.55      0.67      5113\n",
      "           Soul-RnB       0.24      0.08      0.12       199\n",
      "\n",
      "          micro avg       0.70      0.44      0.54     25009\n",
      "          macro avg       0.61      0.36      0.44     25009\n",
      "       weighted avg       0.70      0.44      0.54     25009\n",
      "        samples avg       0.56      0.49      0.50     25009\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\orovi\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_pred = cl3.predict(X_test)\n",
    "my_metrics = metrics.classification_report( y_test, y_pred, target_names=mlb.classes_)\n",
    "print(my_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "80e8f56a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2 0.46757995499835453\n",
      "0.25 0.4748667384589266\n",
      "0.3 0.4727577311930825\n",
      "0.35 0.4701596211564342\n",
      "0.4 0.46299077082335016\n",
      "0.44999999999999996 0.45244240733630214\n",
      "0.5 0.43649228916261634\n"
     ]
    }
   ],
   "source": [
    "yp_pred = np.array(cl3.predict_proba(X_test))\n",
    "for prob in np.linspace(.2,.5, 7):\n",
    "    y_pred = (yp_pred > prob).astype(int)\n",
    "    print(prob, metrics.f1_score(y_test, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3f1e5fcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     precision    recall  f1-score   support\n",
      "\n",
      "              Blues       0.32      0.13      0.18       139\n",
      "          Classical       0.64      0.53      0.58       537\n",
      "            Country       0.20      0.29      0.24       231\n",
      "         Electronic       0.64      0.71      0.68      5267\n",
      "       Experimental       0.63      0.71      0.67      5573\n",
      "               Folk       0.44      0.64      0.52      1613\n",
      "            Hip-Hop       0.54      0.55      0.54      1350\n",
      "       Instrumental       0.52      0.30      0.38      1797\n",
      "      International       0.56      0.37      0.45       732\n",
      "               Jazz       0.43      0.32      0.37       478\n",
      "Old-Time / Historic       0.93      0.76      0.84       161\n",
      "                Pop       0.36      0.29      0.32      1819\n",
      "               Rock       0.69      0.71      0.70      5113\n",
      "           Soul-RnB       0.26      0.05      0.08       199\n",
      "\n",
      "          micro avg       0.59      0.60      0.60     25009\n",
      "          macro avg       0.51      0.45      0.47     25009\n",
      "       weighted avg       0.59      0.60      0.59     25009\n",
      "        samples avg       0.61      0.64      0.60     25009\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\orovi\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_pred = (yp_pred > .35).astype(int)\n",
    "my_metrics = metrics.classification_report( y_test, y_pred, target_names=mlb.classes_)\n",
    "print(my_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c40080",
   "metadata": {},
   "source": [
    "### hidden layer size (400,)\n",
    "\n",
    "NOTE: VERY SLOW!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a8525d8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(alpha=0.001, hidden_layer_sizes=(400,), max_iter=1000,\n",
       "              random_state=53)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl4 = MLPClassifier(max_iter=1000, hidden_layer_sizes=(400,), alpha=0.001, random_state=RANDOM_STATE)\n",
    "cl4.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "305f8da8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     precision    recall  f1-score   support\n",
      "\n",
      "              Blues       0.47      0.10      0.17       139\n",
      "          Classical       0.73      0.47      0.57       537\n",
      "            Country       0.26      0.23      0.24       231\n",
      "         Electronic       0.72      0.57      0.64      5267\n",
      "       Experimental       0.71      0.58      0.64      5573\n",
      "               Folk       0.53      0.54      0.54      1613\n",
      "            Hip-Hop       0.64      0.46      0.53      1350\n",
      "       Instrumental       0.57      0.19      0.29      1797\n",
      "      International       0.66      0.30      0.42       732\n",
      "               Jazz       0.50      0.23      0.32       478\n",
      "Old-Time / Historic       0.95      0.75      0.84       161\n",
      "                Pop       0.45      0.15      0.23      1819\n",
      "               Rock       0.78      0.62      0.69      5113\n",
      "           Soul-RnB       0.47      0.04      0.07       199\n",
      "\n",
      "          micro avg       0.69      0.49      0.57     25009\n",
      "          macro avg       0.60      0.37      0.44     25009\n",
      "       weighted avg       0.67      0.49      0.56     25009\n",
      "        samples avg       0.59      0.54      0.54     25009\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\orovi\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_pred = cl4.predict(X_test)\n",
    "my_metrics = metrics.classification_report( y_test, y_pred, target_names=mlb.classes_)\n",
    "print(my_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fd71facc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2 0.46163336561900686\n",
      "0.25 0.4698236549723124\n",
      "0.3 0.4715551761091227\n",
      "0.35 0.4672156038868742\n",
      "0.4 0.46154914431051036\n",
      "0.44999999999999996 0.45212814481496677\n",
      "0.5 0.44024483731621894\n"
     ]
    }
   ],
   "source": [
    "yp_pred = np.array(cl4.predict_proba(X_test))\n",
    "for prob in np.linspace(.2,.5, 7):\n",
    "    y_pred = (yp_pred > prob).astype(int)\n",
    "    print(prob, metrics.f1_score(y_test, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "09198bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     precision    recall  f1-score   support\n",
      "\n",
      "              Blues       0.32      0.13      0.18       139\n",
      "          Classical       0.64      0.53      0.58       537\n",
      "            Country       0.20      0.29      0.24       231\n",
      "         Electronic       0.64      0.71      0.68      5267\n",
      "       Experimental       0.63      0.71      0.67      5573\n",
      "               Folk       0.44      0.64      0.52      1613\n",
      "            Hip-Hop       0.54      0.55      0.54      1350\n",
      "       Instrumental       0.52      0.30      0.38      1797\n",
      "      International       0.56      0.37      0.45       732\n",
      "               Jazz       0.43      0.32      0.37       478\n",
      "Old-Time / Historic       0.93      0.76      0.84       161\n",
      "                Pop       0.36      0.29      0.32      1819\n",
      "               Rock       0.69      0.71      0.70      5113\n",
      "           Soul-RnB       0.26      0.05      0.08       199\n",
      "\n",
      "          micro avg       0.59      0.60      0.60     25009\n",
      "          macro avg       0.51      0.45      0.47     25009\n",
      "       weighted avg       0.59      0.60      0.59     25009\n",
      "        samples avg       0.61      0.64      0.60     25009\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\orovi\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_pred = (yp_pred > .35).astype(int)\n",
    "my_metrics = metrics.classification_report( y_test, y_pred, target_names=mlb.classes_)\n",
    "print(my_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "87a95421",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.322987780391257"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_test, y_pred,  normalize=True, sample_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82aabdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c26ff4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
